{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单线性回归实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train = np.loadtxt('data/click.csv', delimiter=',', skiprows=1)\n",
    "train_x = train[:, 0]\n",
    "train_y = train[:, 1]\n",
    "\n",
    "theta0 = np.random.rand()\n",
    "theta1 = np.random.rand()\n",
    "\n",
    "# predict function\n",
    "def f(x):\n",
    "    return theta0 + theta1 * x\n",
    "\n",
    "# Target function\n",
    "def E(x, y):\n",
    "    return 0.5 * np.sum((y - f(x)) ** 2)\n",
    "\n",
    "mu = train_x.mean()\n",
    "sigma = train_x.std()\n",
    "def Standardize(x):\n",
    "    return (x - mu) / sigma;\n",
    "\n",
    "# train_z = Standardize(train_x)\n",
    "\n",
    "def DoTraining(xArr, yArr):\n",
    "    ETA = 1e-3\n",
    "    EPSILON = 1e-2\n",
    "    stdXArr = Standardize(xArr)\n",
    "    error = E(stdXArr, yArr)\n",
    "    diff = 1.0\n",
    "    count = 0\n",
    "    global theta0\n",
    "    global theta1\n",
    "    while diff > EPSILON :\n",
    "        nTheta0 = theta0 - ETA * np.sum(f(stdXArr) - yArr)\n",
    "        nTheta1 = theta1 - ETA * np.sum((f(stdXArr) - yArr) * stdXArr)\n",
    "        theta0 = nTheta0\n",
    "        theta1 = nTheta1\n",
    "        \n",
    "        cur_error = E(stdXArr, yArr)\n",
    "        diff = error - cur_error\n",
    "        error = cur_error\n",
    "\n",
    "        count += 1\n",
    "        #log = 'times:{} theta0:{:.3f} theta1:{:.3f} diff:{:.4f}'\n",
    "        #print(log.format(count, theta0, theta1, diff))\n",
    "    return stdXArr\n",
    "\n",
    "stdXArr = DoTraining(train_x, train_y)\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(stdXArr, train_y, 'o')\n",
    "plt.plot(x, f(x))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thetas_3 = np.random.rand(3)\n",
    "\n",
    "def To_matrix(x):\n",
    "    return np.vstack([np.ones(x.shape[0]), x, x ** 2]).T\n",
    "\n",
    "def Standardize(x, mu, sigma):\n",
    "    return (x - mu) / sigma;    \n",
    "\n",
    "def F(x):\n",
    "    return np.dot(x, thetas_3)\n",
    "    \n",
    "def Error(x, y):\n",
    "    return 0.5 * np.sum((y - F(x)) ** 2)\n",
    "\n",
    "train = np.loadtxt('data/click.csv', delimiter=',', skiprows=1)\n",
    "train_x = train[:, 0]\n",
    "train_y = train[:, 1]\n",
    "mu = train_x.mean()\n",
    "sigma = train_x.std()\n",
    "\n",
    "train_z = Standardize(train_x, mu, sigma)\n",
    "X = To_matrix(train_z)\n",
    "def training():\n",
    "    diff = 1.0\n",
    "    EPSILON = 0.01\n",
    "    ETA = 1e-3\n",
    "    error = Error(X, train_y)\n",
    "    global thetas_3\n",
    "    while diff > EPSILON :\n",
    "        thetas_3 = thetas_3 - ETA * np.dot(F(X) - train_y, X)\n",
    "        current_error = Error(X, train_y)\n",
    "        diff = error - current_error\n",
    "        error = current_error\n",
    "\n",
    "training()\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.plot(x, f(To_matrix(x)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = np.loadtxt('data/images1.csv', delimiter=',', skiprows=1)\n",
    "x_data = train_data[:, 0:2]\n",
    "y_data = train_data[:, 2]\n",
    "\n",
    "w = np.random.rand(2)\n",
    "def F(x) :\n",
    "    v = np.dot(w, x)\n",
    "    if v >= 0 : \n",
    "        return 1\n",
    "    else :\n",
    "        return -1\n",
    "\n",
    "def classify_training() : \n",
    "    epoch = 10\n",
    "    count = 0\n",
    "    global w\n",
    "    for _ in range(epoch) : \n",
    "        for x, y in zip(x_data, y_data) :\n",
    "            if F(x) != y :\n",
    "                w = w + y * x\n",
    "                count += 1\n",
    "\n",
    "classify_training()\n",
    "\n",
    "plt.plot(x_data[y_data == 1, 0], x_data[y_data == 1, 1], 'o')\n",
    "plt.plot(x_data[y_data == -1, 0],x_data[y_data == -1, 1], 'x')\n",
    "x1 = np.arange(0, 500)\n",
    "plt.plot(x1, -w[0] / w[1] * x1, linestyle='dashed')\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Standardize(X, mu, sigma):\n",
    "    return (X - mu) / sigma\n",
    "\n",
    "def F(x, theta) :\n",
    "    return 1.0 / (1.0 + np.exp(-np.dot(x, theta)))\n",
    "\n",
    "def LogisticRegression(X, train_y, theta) :\n",
    "    EPOCH = 5000\n",
    "    ETA = 1e-3\n",
    "\n",
    "    for _ in range(EPOCH) :\n",
    "        theta = theta - ETA * np.dot(F(X, theta) - train_y, X)\n",
    "    return theta    \n",
    "\n",
    "train_data = np.loadtxt('data/images2.csv', delimiter=',', skiprows=1)\n",
    "x_data = train_data[:, 0:2]\n",
    "mu = x_data.mean(axis=0)\n",
    "sigma = x_data.std(axis=0)\n",
    "X0 = Standardize(x_data, mu, sigma)\n",
    "newRow = np.ones([X0.shape[0], 1])\n",
    "X = np.hstack([newRow, X0])\n",
    "y_data = train_data[:, 2]\n",
    "\n",
    "thetaV3 = np.random.rand(3)\n",
    "thetaV3 = LogisticRegression(X, y_data, thetaV3)\n",
    "\n",
    "##Draw the result\n",
    "x0 = np.linspace(-2, 2, 100)\n",
    "plt.plot(X0[y_data == 1, 0], X0[y_data == 1, 1], 'o')\n",
    "plt.plot(X0[y_data == 0, 0], X0[y_data == 0, 1], 'x')\n",
    "plt.plot(x0, -(thetaV3[0] + thetaV3[1] * x0) / thetaV3[2], linestyle='dashed')\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引用\n",
    "1. https://research.facebook.com/publications/avatars-grow-legs-generating-smooth-human-motion-from-sparse-tracking-inputs-with-diffusion-model/\n",
    "2. https://github.com/fengdu78/deeplearning_ai_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
